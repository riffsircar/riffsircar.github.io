
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Jon Barron and Abhishek Kar and Saurabh Gupta and Deepak Pathak*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 400
  }
  heading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 19px;
    font-weight: 1000
  }
  strong {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 800
  }
  strongred {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    font-weight: 600
  }
  pageheading {
    font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 38px;
    font-weight: 400
  }
  </style>
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <script type="text/javascript">
    function hideallbibs()
{
    var el = document.getElementsByTagName("div") ;
    for (var i = 0 ; i < el.length ; ++i) {
        if (el[i].className == "paper") {
            var bib = el[i].getElementsByTagName("pre") ;
            if (bib.length > 0) {
                bib [0] .style.display = 'none' ;
            }
        }
    }
}

function togglebib(paperid)
{
    var paper = document.getElementById(paperid) ;
    var bib = paper.getElementsByTagName('pre') ;
    if (bib.length > 0) {
        if (bib [0] .style.display == 'none') {
            bib [0] .style.display = 'block' ;
        } else {
            bib [0] .style.display = 'none' ;
        }
    }
}

function toggleblock(blockId)
{
   var block = document.getElementById(blockId);
   if (block.style.display == 'none') {
    block.style.display = 'block' ;
   } else {
    block.style.display = 'none' ;
   }
}

function hideblock(blockId)
{
   var block = document.getElementById(blockId);
   block.style.display = 'none' ;
}

// scramble.js
//
// 2011, Jeff Donahue (http://jeffdonahue.com/).
// license: you can use this if you want to i guess

function scrambledString(tag, objName, initScrambledString, initScrambledStringIndices) {
	this.tag = tag;
	this.objName = objName;
	this.string = initScrambledString;
	this.indices = initScrambledStringIndices;
	this.rescramble = rescramble;
	this.initAnimatedBubbleSort = initAnimatedBubbleSort;
	this.bubbleSortStep = bubbleSortStep;
	this.bubbleSortBookmark = 0;

	this.rescramble();
	this.tag.innerHTML = this.string + ' <a href="#" onClick="' + this.objName + '.initAnimatedBubbleSort();return false;">unscramble</a>';
}

function rescramble() {
	for (i = 0; i < this.indices.length; i++) {
		indexToMove = Math.floor(Math.random() * (this.indices.length - i));
		charIndexRemoved = this.indices.splice(indexToMove, 1);
		this.indices = this.indices.concat(charIndexRemoved);
		scrambledStringTemp = this.string.substring(0, indexToMove) +
			this.string.substring(indexToMove + 1) +
			this.string.substring(indexToMove, indexToMove + 1);
		this.string = scrambledStringTemp;
	}
}

function initAnimatedBubbleSort() {
	this.interval = setInterval(this.objName + '.bubbleSortStep()', 12);
}

function bubbleSortStep() {		
	if (this.bubbleSortBookmark >= this.indices.length - 1) {
		this.bubbleSortBookmark = 0;
	}
	for (i = this.bubbleSortBookmark; i < this.indices.length - 1; i++) {
		if (i == 0) {
			this.changed = 0;
		}
		if (this.indices[i] > this.indices[i + 1]) {
			this.changed = 1;
			tempIndex = this.indices[i];
			this.indices[i] = this.indices[i + 1];
			this.indices[i + 1] = tempIndex;
			tempArrange = this.string.substring(0, i) +
				this.string.substring(i + 1, i + 2) + 
				this.string.substring(i, i + 1) +
				this.string.substring(i + 2);
			this.string = tempArrange;
			this.tag.innerHTML = this.string;
			this.bubbleSortBookmark = i;
			break;
		}
	}
	this.bubbleSortBookmark = i;
	if (!this.changed) {
		clearInterval(this.interval);
	}
}    
    
  </script>
  <title>Anurag Sarkar</title>
  <meta name="Anurag Sarkar's Homepage" http-equiv="Content-Type" content="Anurag Sarkar's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- Start : Google Analytics Code -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-64069893-1', 'auto');
    ga('send', 'pageview');
  </script>
</head>

<body>
<table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
    <!-- <font size="7">Anurag Sarkar</font><br> -->
    <pageheading>Anurag Sarkar</pageheading><br>
    <b>email</b>:
    <font id="email" style="display:inline;">
      <noscript><i>Please enable Javascript to view</i></noscript>
    </font>
    <script>
    emailScramble = new scrambledString(document.getElementById('email'),
        'emailScramble', 'sarkar.an@husky.neu.edu',
        [12,13,15,1,8,7,2,5,4,11,18,10,17,3,22,16,6,19,9,14,21,20]);
    </script>
  </p>

  <tr>
    <td width="32%" valign="top"><!-- <a href="images/aumingi.jpg"><img src="images/aumingi.jpg" width="100%" style="border-radius:15px"></a> -->
    <p align=center>
    | <a href="assets/files/CV.pdf">CV</a> |
    <a href="bio.text" target="_blank">Bio</a> |
    <a href="https://scholar.google.com/citations?hl=en&user=VVnRDggAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> |<br/>|
    <!-- <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-132.pdf">Phd Thesis</a> | -->
    <a href="https://github.com/riffsircar">Github</a> |
    <a href="https://twitter.com/riffsircar">Twitter</a> |
    </p>
    </td>
    <td width="68%" valign="top" align="justify">
    <p>I spend most of my time trying to not eat pizza.</p>

    </td>
  </tr>
</table>

<!--
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td>
    <sectionheading>&nbsp;&nbsp;News</sectionheading>
    <ul>
    <li> <a href="#ASSEMBLIES19">Modular assemblies</a> won the <a href="https://virtualcreatures.github.io/" target="_blank">Virtual Creatures Competition</a> at GECCO'19!<br></li>
    <li> Co-organized the <a href="https://futurecv.github.io/" target="_blank">"Computer Vision After 5 years"</a> workshop at CVPR'19.</li>
    <li> Co-organized the <a href="https://tarl2019.github.io/" target="_blank">Task Agnostic Reinforcement Learning</a> workshop at ICLR'19.</li>
    <li> <a href="#ICLR19">ICLR'19 paper</a> on large-scale curiosity-driven learning covered in <a href="https://pathak22.github.io/large-scale-curiosity/index.html#media">The Economist and other media articles</a>.</li>
    <li> Co-organized the <a href="http://pocv18.eecs.berkeley.edu/">Action, Perception and Organization</a> workshop at ECCV'18.</li>
    <li> Received the <a href="https://research.fb.com/announcing-the-2018-cohort-of-facebook-fellows-and-emerging-scholars/" target="_blank">2018 Facebook Graduate Fellowship</a>. Thanks, Facebook!</li>
    <li> <a href="#ICML18">ICML'18 paper</a> on human exploration got covered in <a href="https://rach0012.github.io/humanRL_website/index.html#media">MIT Tech Review and other media articles</a>.</li>
    <li> Received the <a href="https://snapresearchfellowship.splashthat.com/" target="_blank">2017 Snap Inc. Research Fellowship Award</a>. Thanks, Snapchat!</li>
    <li> <a href="#ICML17">ICML'17 paper</a> on curiosity-driven exploration got covered in <a href="https://pathak22.github.io/noreward-rl/index.html#media">MIT Tech Review and other media articles</a>.</li>
    <li> Received the <a href="https://www.nvidia.com/en-us/research/graduate-fellowships/2017/deepak-pathak/" target="_blank">2017 NVIDIA Graduate Fellowship</a>. Thanks, NVIDIA! Complete list <a href="https://www.nvidia.com/en-us/research/graduate-fellowships/" target="_blank">here</a>.</li>
    </ul>
  </td></tr>
</table> -->

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Publications</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
  <tr>
    <td width="33%" valign="top" align="center"><a href="https://pathak22.github.io/modular-assemblies/"><img src="images/assemblies19.gif" alt="sym" width="90%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="https://pathak22.github.io/modular-assemblies/" id="ASSEMBLIES19">
      <heading>Game Design using Creative AI</heading></a><br>
      <b>Anurag Sarkar</b><br>
      NeurIPS 2019 Workshop on Machine Learning for Creativity and Design<br>
      </p>

      <div class="paper" id="game19">
      <a href="https://pathak22.github.io/modular-assemblies/">webpage</a> |
      <a href="https://pathak22.github.io/modular-assemblies/resources/assemblies.pdf">pdf</a> |
      <a href="javascript:toggleblock('game19_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('game19')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/1902.05546v2">arXiv</a> |
      <a href="https://youtu.be/cg-RdkPtRiQ">video</a> |
      <a href="https://pathak22.github.io/modular-assemblies/index.html#sourceCode">code</a>

      <p align="justify"> <i id="game19_abs"> Creative AI refers to the application of AI techniques, primarily machine learning, for performing creative tasks such as generating art and music. In this paper, we present exploratory work that demonstrates and argues for leveraging such creative AI techniques for game design. We train variational autoencoders (VAEs) on levels from the games \textit{Super Mario Bros.} and \textit{Kid Icarus} and show how the affordances of the learned models can help inform co-creative game and level design, similar to applications of creative AI and machine learning in visual art and music.</i></p>

<pre xml:space="preserve">
@inproceedings{sarkar19game,
  Author = {Sarkar, Anurag},
  Title = {Game Design using Creative AI},
  Booktitle = {NeurIPS 2019 Workshop on Machine Learning for Creativity and Design},
  Year = {2019}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="top" align="center"><a href="https://pathak22.github.io/hierarchical-imitation/"><img src="images/neurips19.jpg" alt="sym" width="90%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="https://pathak22.github.io/hierarchical-imitation/" id="NEURIPS19">
      <heading>Using a Disjoint Skill Model for Game and Task Difficulty in Human Computation Games</heading></a><br>
      <b>Anurag Sarkar</b>, Seth Cooper<br>
      CHI Play, 2019
      </p>

      <div class="paper" id="disjoint19">
      <a href="https://pathak22.github.io/hierarchical-imitation/">webpage</a> |
      <a href="https://pathak22.github.io/hierarchical-imitation/resources/paper.pdf">pdf</a> |
      <a href="javascript:toggleblock('disjoint19_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('disjoint19')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/1911.09676">arXiv</a> |
      <a href="https://youtu.be/eWBkDuNFEKA">video</a> |
      <a href="https://github.com/pathak22/hierarchical-imitation/">code</a>

      <p align="justify"> <i id="disjoint19_abs">Prior research has used player rating systems to balance difficulty in human computation games (HCGs) without having to modify their levels by assigning ratings to levels to indicate level difficulty. Skill chains have also been used to define difficulty progressions for such games. Both these methods typically involve associating a level with a single rating or set of skills as being representative of the difficulty of both the in-game mechanics of the level and the complexity of the task that it models, taken together as a single unit. Though effective, this may not be suitable for HCGs where the game and the task being modeled require different sets of skills and abilities. To this end, we introduce a disjoint skill model that separately tracks game and task skill and difficulty in a 2D platformer HCG. We find that the disjoint model enables players to solve more difficult tasks compared to a baseline model.</i></p>

<pre xml:space="preserve">
@inproceedings{sarkar19disjoint,
  Author = {Sarkar, Anurag and Cooper, Seth},
  Title = {Using a Disjoint Skill Model for Game and Task Difficulty in Human Computation Games},
  Booktitle = {Proceedings of the 2019 Annual Symposium on Computer-Human Interaction in Play},
  Year = {2019}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="top" align="center"><a href="https://pathak22.github.io/exploration-by-disagreement/"><img src="images/icml19.gif" alt="sym" width="90%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="https://pathak22.github.io/exploration-by-disagreement/" id="ICML19">
      <heading>Controllable Level Blending between Games using Variational Autoencoders</heading></a><br>
      <b>Anurag Sarkar</b>, Zhihan Yang, Seth Cooper<br>
      AIIDE 2019 Workshop on Experimental AI in Games (EXAG)<br>
      </p>

      <div class="paper" id="controllable19">
      <a href="https://pathak22.github.io/exploration-by-disagreement/">webpage</a> |
      <a href="https://pathak22.github.io/exploration-by-disagreement/resources/icml19.pdf">pdf</a> |
      <a href="javascript:toggleblock('controllable19_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('controllable19')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/1906.04161">arXiv</a> |
      <a href="https://pathak22.github.io/exploration-by-disagreement/index.html#sourceCode">code</a> |
      <a href="https://youtu.be/POlrWt32_ec">video</a> |
      <a href="https://videoken.com/embed/D0UmVbbJxS8?tocitem=89">oral talk</a>
      <!-- <br> -->

      <p align="justify"> <i id="controllable19_abs">Previous work explored blending levels from existing games to create levels for a new game that mixes properties of the original games. In this paper, we use Variational Autoencoders (VAEs) for improving upon such techniques. VAEs are artificial neural networks that learn and use latent representations of datasets to generate novel outputs. We train a VAE on level data from \textit{Super Mario Bros.} and \textit{Kid Icarus}, enabling it to capture the latent space spanning both games. We then use this space to generate level segments that combine properties of levels from both games. Moreover, by applying evolutionary search in the latent space, we evolve level segments satisfying specific constraints. We argue that these affordances make the VAE-based approach especially suitable for co-creative level design and compare its performance with similar generative models like the GAN and the VAE-GAN.</i></p>

<pre xml:space="preserve">
@inproceedings{sarkar19controllable,
  Author = {Sarkar, Anurag and Yang, Zhihan and Cooper, Seth},
  Title = {Controllable Level Blending between Games using Variational Autoencoders},
  Booktitle = {Proceedings of the EXAG Workshop at AIIDE},
  Year = {2019}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="center" align="center"><a href="https://pathak22.github.io/large-scale-curiosity/"><img src="images/iclr19.jpg" alt="sym" width="90%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="https://pathak22.github.io/large-scale-curiosity/" id="ICLR19">
      <heading>Using Rating Arrays to Estimate Score Distributions for Player-versus-Level Matchmaking</heading></a><br>
      <b>Anurag Sarkar</b>, Seth Cooper<br>
      <!-- <em>International Conference on Learning Representations (ICLR)</em>, 2019<br> -->
      Foundations of Digital Games, 2019<br>
      </p>

      <div class="paper" id="arrays19">
      <a href="https://pathak22.github.io/large-scale-curiosity/">webpage</a> |
      <a href="https://pathak22.github.io/large-scale-curiosity/resources/largeScaleCuriosity2018.pdf">pdf</a> |
      <a href="javascript:toggleblock('arrays19_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('arrays19')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/1808.04355">arXiv</a> |
      <a href="https://youtu.be/l1FqtAHfJLI">video</a> |
      <a href="https://github.com/openai/large-scale-curiosity">code</a>
      <br>

      <p align="justify"> <i id="arrays19_abs">Rating systems (like Elo and Glicko-2) have previously been used for predicting the expected score that a player will achieve on a level. We present an approach that predicts not a single score, but an approximate cumulative distribution function over possible scores. This approach assigns each level an array of multiple ratings for different score thresholds. Our long-term goal is twofold: first, to dynamically change level difficulty for each player by using this CDF to tailor the target score required to complete a level; second, in human computation games (HCGs), to identify players capable of setting new high scores that could correspond to improved solutions to underlying tasks. To move towards this goal, we explore the rating array approach using two datasets: one gathered from the HCG \textit{Paradox}, and one generated from idealized players and levels. We examine the accuracy of the CDF and the expected scores it predicts, as well as its use in serving levels to players who could set new high scores.</i></p>

<pre xml:space="preserve">
@inproceedings{sarkar19arrays,
  Author = {Sarkar, Anurag and Cooper, Seth},
  Title = {Using Rating Arrays to Estimate Score Distributions for Player-versus-Level Matchmaking},
  Booktitle = {Proceedings of the Foundations of Digital Games},
  Year = {2019}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="top" align="center"><a href="https://pathak22.github.io/seg-by-interaction/"><img src="images/cvprw18.jpg" alt="sym" width="90%" style="border-style: none"></a></td>
    <td width="67%" valign="top">
      <p><a href="https://pathak22.github.io/seg-by-interaction/" id="CVPRW18">
      <heading>Inferring and Comparing Game Difficulty Curves using Player-versus-Level Match Data</heading></a><br>
      <b>Anurag Sarkar</b>, Seth Cooper<br>
      IEEE Conference on Games, 2019<br>
      </p>

      <div class="paper" id="inferring19">
      <a href="https://pathak22.github.io/seg-by-interaction/">webpage</a> |
      <a href="papers/cvprw18.pdf">pdf</a> |
      <a href="javascript:toggleblock('inferring19_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('inferring19')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/1806.08354">arXiv</a> |
      <a href="https://pathak22.github.io/seg-by-interaction/index.html#sourceCode">code</a>
      <br>

      <p align="justify"> <i id="inferring19_abs">Prior work has focused on formalizing difficulty curves by using function composition to give precise definitions to curves and their transformations. However, the proposed framework was demonstrated using a single game, and the curves and transformations were defined with respect to the game's ratings-based dynamic difficulty system. In this work, we infer difficulty curves from gameplay data using a method that is based on the aforementioned difficulty system but that can also be generalized to other games for which information on player-vs-level win/loss outcomes is available. Moreover, since this method uses the same difficulty mechanism as past work, it lets us similarly leverage function composition to compare difficulty curves across games, having either a fixed or dynamic level ordering, using a clearly defined vocabulary. We use four different games to demonstrate our method, which relies on an adjustment to traditional playback of ratings-based match data, which we also present in this work.</i></p>

<pre xml:space="preserve">
@inproceedings{sarkar19inferring,
      Author = {Sarkar, Anurag and Cooper, Seth},
      Title = {Inferring and Comparing Game Difficulty Curves using Player-versus-Level Match Data},
      Booktitle = {Proceedings of the IEEE Conference on Games},
      Year = {2019}
  }
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="center" align="center"><a href="https://arxiv.org/abs/1807.07560"><img src="images/compgan18.jpg" alt="sym" width="90%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="https://arxiv.org/abs/1807.07560" id="transforming19">
      <heading>Transforming Game Difficulty Curves using Function Composition</heading></a><br>
      <b>Anurag Sarkar</b>, Seth Cooper<br>
      CHI 2019<br>     
      </p>

      <div class="paper" id="transforming19">
      <a href="https://arxiv.org/abs/1807.07560">arXiv pdf</a> |
      <a href="javascript:toggleblock('transforming19_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('transforming19')" class="togglebib">bibtex</a>
      <!-- <a href="https://pathak22.github.io/large-scale-curiosity/index.html#sourceCode">code</a> -->
      <br>

      <p align="justify"> <i id="transforming19_abs">Player engagement within a game is often influenced by its difficulty curve: the pace at which in-game challenges become harder. Thus, finding an optimal difficulty curve is important. In this paper, we present a flexible and formal approach to transforming game difficulty curves by leveraging function composition. This allows us to describe changes to difficulty curves, such as making them ``smoother'', in a more precise way. In an experiment with 400 players, we used function composition to modify the existing difficulty curve of the puzzle game \textit{Paradox} to generate new curves. We found that transforming difficulty curves in this way impacted player engagement, including the number of levels completed and the estimated skill needed to complete those levels, as well as perceived competence. Further, we found some transformed curves dominated others with respect to engagement, indicating that different design goals can be traded-off by considering a subset of curves.</i></p>

<pre xml:space="preserve">
@inproceedings{sarkar19transforming,
  Author = {Sarkar, Anurag and Cooper, Seth},
  Title = {Transforming Game Difficulty Curves using Function Composition},
  Booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing},
  Year = {2019}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="center" align="center"><a href="http://pathak22.github.io/zeroshot-imitation/"><img src="images/iclr18_1.gif" alt="sym" width="65%" border="1" style="border-color:black"><hr style="height:0pt; visibility:hidden; margin:0"/><img src="images/iclr18_2.gif" alt="sym" width="65%" border="1" style="border-color:black"></a></td>
    <td width="67%" valign="top">
      <p><a href="http://pathak22.github.io/zeroshot-imitation/" id="ICLR18">
      <heading>Blending Levels from Different Games using LSTMs</heading></a><br>
      <b>Anurag Sarkar</b>, Seth Cooper<br>
      EXAG 2018<br>
      </p>

      <div class="paper" id="blending18">
      <a href="http://pathak22.github.io/zeroshot-imitation/">webpage</a> |
      <!-- <a href="http://pathak22.github.io/zeroshot-imitation/resources/iclr18.pdf">pdf</a> | -->
      <a href="javascript:toggleblock('blending18_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('blending18')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/1804.08606" target="_blank">arXiv</a> |
      <a href="http://pathak22.github.io/zeroshot-imitation/index.html#sourceCode">code</a> |
      <a href="http://pathak22.github.io/zeroshot-imitation/index.html#demoVideos">videos</a> |
      <a href="https://openreview.net/forum?id=BkisuzWRW" target="_blank">open-review</a> |
      <a href="https://www.dropbox.com/s/36efg1t3qn6i495/2018_04_ZeroShotImitation.pptx">slides</a>
      <br>

      <p align="justify"> <i id="blending18_abs">Recent work has shown machine learning approaches to be effective in training models on existing game data for informing procedural generation of novel content. Specifically, ML techniques have successfully used existing game levels to train models for generating new levels and blending existing ones. Such blending of not just levels, but entire games, has also been proposed as a possible means of generating new games. In this paper, we build on these works by training Long Short Term Memory recurrent neural networks on level data for two separate platformer games---\textit{Super Mario Bros.} and \textit{Kid Icarus}---and use these models to create new levels that are blends of levels from both games, thus creating a level generator for a novel, third game.</i></p>

<pre xml:space="preserve">
@inproceedings{sarkar18blending,
    Author = {Sarkar, Anurag and Cooper, Seth},
    Title = {Blending Levels from Different Games using LSTMs},
    Booktitle = {Proceedings of the EXAG Workshop at AIIDE},
    Year = {2018}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="center" align="center"><a href="https://rach0012.github.io/humanRL_website/"><img src="images/icml18.png" alt="sym" width="90%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="https://rach0012.github.io/humanRL_website/" id="ICML18">
      <heading>Desire Path-inspired Procedural Placement of Coins in a Platformer Game</heading></a><br>
      <b>Anurag Sarkar</b>, Varun Sriram, Riddhi Padte, Jeffrey Cao, Seth Cooper<br>
      EXAG 2018<br>
      </p>

      <div class="paper" id="desire18">
      <a href="https://rach0012.github.io/humanRL_website/">webpage</a> |
      <a href="papers/icml18.pdf">pdf</a> |
      <a href="javascript:toggleblock('desire18_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('desire18')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/1802.10217">arXiv</a> |
      <a href="https://youtu.be/Ol0-c9OE3VQ" target="_blank">video</a>
      <br>

      <p align="justify"> <i id="desire18_abs">Many games feature collectible items that are manually placed by a designer. In this work, we developed an algorithm, inspired by \emph{desire paths}, for automatically placing collectible coins in a platformer game. Desire paths are paths naturally formed where people walk, rather than those laid down artificially, and are often the shortest or easiest route between an origin and destination. Our algorithm uses player trajectories to find paths along which to place the coins for each level. We ran an experiment comparing path-based placement to other placement methods. Although we did not find a difference in total time spent playing or likelihood of finishing the game, our results suggest that path-based placement leads to players collecting more coins in less time than with designer or randomly placed coins. Further, we found that players played similarly when coins were either path-based or there were no coins, and similarly when coins were either placed by a designer or randomly.</i></p>

<pre xml:space="preserve">
@inproceedings{sarkar18desire,
    Author = {Sarkar, Anurag and Sriram, Varun and Padte, Riddhi and Cao, Jeffrey and Cooper, Seth},
    Title = {Desire Path-inspired Procedural Placement of Coins in a Platformer Game},
    Booktitle = {Proceedings of the Experimental AI in Games Workshop at AIIDE},
    Year = {2018}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="center" align="center"><a href="http://pathak22.github.io/noreward-rl/"><img src="images/icml17_1.gif" alt="sym" width="49%" style="border-radius:15px">&nbsp;<img src="images/icml17_2.gif" alt="sym" width="49%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="http://pathak22.github.io/noreward-rl/" id="ICML17">
      <heading>Comparing Paid and Volunteer Recruitment in Human Computation Games</heading></a><br>
      <b>Anurag Sarkar</b>, Seth Cooper<br>
      FDG, 2018<br>
      </p>
      <div class="paper" id="icml17">
      <a href="http://pathak22.github.io/noreward-rl/">webpage</a> |
      <a href="http://pathak22.github.io/noreward-rl/resources/icml17.pdf">pdf</a> |
      <a href="javascript:toggleblock('comparing18_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('comparing18')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/1705.05363">arXiv</a> |
      <a href="http://pathak22.github.io/noreward-rl/index.html#sourceCode">code</a> |
      <a href="http://pathak22.github.io/noreward-rl/index.html#demoVideo">video</a> |
      <a href="http://pathak22.github.io/noreward-rl/index.html#media">in the media</a>
      <br/>

      <p align="justify"> <i id="comparing18_abs">Paid platforms like Mechanical Turk are popular for recruiting players for playtesting and experiments. However, it is unclear if paid players have similar behavior or experiences as volunteers (i.e. players recruited for free through banner ads or game portals). In this work, we studied the impact of recruitment within human computation games, using two experiments. First, we compared voluntary recruitment versus paid recruitment with different compensation levels. We found that the highest paid players completed more levels (i.e. achieved a higher \textit{volume} of completed tasks) and reported greater engagement than both volunteers and players paid less while volunteers completed levels of higher difficulty (i.e. achieved a higher \textit{quality} of completed tasks) than paid players. Additionally, we also varied both recruitment strategy and the game's design and found no interaction effects, suggesting that while differences exist between volunteer and paid players, experimental changes do not impact those players differently.</i></p>

<pre xml:space="preserve">
@inproceedings{sarkar18comparing,
    Author = {Sarkar, Anurag and Cooper, Seth},
    Title = {Comparing Paid and Volunteer Recruitment in Human Computation Games},
    Booktitle = {Proceedings of the Foundations of Digital Games},
    Year = {2018}
}</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="center" align="center"><a href="https://junyanz.github.io/BicycleGAN"><img src="images/nips17.gif" alt="sym" width="90%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="https://junyanz.github.io/BicycleGAN" id="NIPS17">
      <heading>Meet your Match Rating: Providing Skill Information and Choice in Player-versus-Level Matchmaking</heading></a><br>
      <b>Anurag Sarkar</b>, Seth Cooper<br>
      FDG 2018
      </p>

      <div class="paper" id="nips17">
      <a href="https://junyanz.github.io/BicycleGAN">webpage</a> |
      <a href="papers/nips17.pdf">pdf</a> |
      <a href="javascript:toggleblock('meet18_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('meet18')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/1711.11586">arXiv</a> |
      <a href="https://github.com/junyanz/BicycleGAN">code</a> |
      <a href="https://youtu.be/JvGysD2EFhw">video</a>
      <br>

      <p align="justify"> <i id="meet18_abs">Previous work has demonstrated the effectiveness of rating system-based matchmaking for level ordering within the particular constraints of human computation games. However, players were not informed about the rating system, nor allowed to choose the difficulty of upcoming levels. Informing players of the ratings used in the system and offering them choice of upcoming level difficulty may enhance feelings of competence and control respectively, thereby further improving player engagement. Thus, we attempted to improve player experience by both exposing players to the underlying rating system, as well as offering them choice of level difficulty. We found that players cognizant of ratings both attempted and completed more levels than those who were not. Though additionally offering choice did not significantly affect behavior, we found that player choice was influenced by the outcome of the preceding level. Moreover, we did not observe any significant impact on self-reported measures of subjective experience.</i></p>

<pre xml:space="preserve">
@inproceedings{sarkar18meet,
    Author = {Sarkar, Anurag and Cooper, Seth},
    Title = {Meet your Match Rating: Providing Skill Information and Choice in Player-versus-Level Matchmaking},
    Booktitle = {Proceedings of the Foundations of Digital Games},
    Year = {2018}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="top" align="center"><a href="unsupervised_video/"><img src="images/cvpr17.jpg" alt="sym" width="90%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="unsupervised_video/" id="CVPR17">
      <heading>Level Difficulty and Player Skill Prediction in Human Computation Games</heading></a><br>
      <b>Anurag Sarkar</b>, Seth Cooper<br>
      AIIDE 2017
      </p>

      <div class="paper" id="cvpr17">
      <a href="unsupervised_video/">webpage</a> |
      <a href="papers/cvpr17.pdf">pdf</a> |
      <a href="javascript:toggleblock('level17_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('level17')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/1612.06370">arXiv</a> |
      <a href="unsupervised_video/index.html#sourceCode">code</a>
      <br>
      
      <p align="justify"> <i id="level17_abs">Human computation games (HCGs) often suffer from low player retention. This may be due to the constraints placed on level and game design from the real-world application of the game. Previous work has suggested using player rating systems (such as Elo, Glicko-2, or TrueSkill) as a basis for matchmaking between HCG levels and players, as a means to improve difficulty balancing and thus player retention. Such rating systems typically start incoming entities with a default rating.  However, when applied to HCGs, incoming entities may have useful information associated with them, such as player behavior during tutorials and properties of the tasks underlying the levels.  In this work, we examined using features derived from player behavior and level properties to predict their eventual Glicko-2 ratings in the HCG \game{Paradox}. We found that using regression produced rating estimates closer to the actual ratings than default or baseline average ratings. The use of rating systems allows a unified approach to predicting both player skill and level difficulty.</i></p>

<pre xml:space="preserve">
@inproceedings{sarkar17level,
    Author = {Sarkar, Anurag and Cooper, Seth},
    Title = {Level Difficulty and Player Skill Prediction in Human Computation Games},
    Booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
    Year = {2017}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="top" align="center"><a href="context_encoder/"><img src="images/cvpr16.jpg" alt="sym" width="75%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="context_encoder/" id="CVPR16">
      <heading>Predicting Human Computation Game Scores with Player Rating Systems</heading></a><br>
      Michael Williams, <b>Deepak Pathak</b>, Seth Cooper<br>
      ICEC, 2017
      </p>

      <div class="paper" id="cvpr16">
      <a href="context_encoder/">webpage</a> |
      <a href="papers/cvpr16.pdf">pdf w/ supp</a> |
      <a href="javascript:toggleblock('predicting17_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('predicting17')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/1604.07379">arXiv</a> |
      <a href="https://github.com/pathak22/context-encoder">code</a> |
      <a href="context_encoder/resources/ContextEncoder_Slides.pptx">slides</a>

      <p align="justify"> <i id="predicting17_abs">Human computation games aim to apply human skill toward real-world problems through gameplay.  Such games may suffer from poor retention, potentially due to the constraints that using pre-existing problems place on game design. Previous work has proposed using player rating systems and matchmaking to balance the difficulty of human computation games, and explored the use of rating systems to predict the outcomes of player attempts at levels. However, these predictions were win/loss, which required setting a score threshold to determine if a player won or lost. This may be undesirable in human computation games, where what scores are possible may be unknown. In this work, we examined the use of rating systems for predicting scores, rather than win/loss, of player attempts at levels. We found that, except in cases with a narrow range of scores and little prior information on player performance, Glicko-2 performs favorably to alternative methods.</i></p>

<pre xml:space="preserve">
@inproceedings{williams17predicting,
    Author = {Williams, Michael and Sarkar, Anurag and Cooper, Seth},
    Title = {Predicting Human Computation Game Scores with Player Rating Systems},
    Booktitle = {ICEC},
    Year = {2017}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="center"><a href="images/jmlr16.jpg"><img src="images/jmlr16.jpg" alt="sym" width="90%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="papers/jmlr16.pdf" id="JMLR16">
      <heading>Engagement Effects of Player Rating System-based Matchmaking for Level Ordering in Human Computation Games</heading></a><br>
      <b>Anurag Sarkar</b>, Michael Williams, Sebastian Deterding, Seth Cooper<br>
      FDG, 2017
      </p>

      <div class="paper" id="jmlr16">
      <a href="papers/jmlr16.pdf">pdf</a> |
      <a href="javascript:toggleblock('engagement17_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('engagement17')" class="togglebib">bibtex</a> |
      <a href="http://jmlr.org/papers/volume17/15-223/15-223.pdf">jmlr</a>

      <p align="justify"> <i id="engagement17_abs">Human computation games lack established ways of balancing the difficulty of tasks or levels served to players, potentially contributing to their low engagement rates. Traditional player rating systems have been suggested as a potential solution: using them to rate both players and tasks could estimate player skill and task difficulty and fuel player-task matchmaking. However, neither the effect of difficulty balancing on engagement in human computation games nor the use of player rating systems for this purpose has been empirically tested. We therefore examined the engagement effects of using the Glicko-2 player rating system to order tasks in the human computation game \textit{Paradox}. An online experiment (n=294) found that both matchmaking-based and pure difficulty-based ordering of tasks led to significantly more attempted and completed levels than random ordering. Additionally, both matchmaking and random ordering led to significantly more difficult tasks being completed than pure difficulty-based ordering. We conclude that poor balancing contributes to poor engagement in human computation games, and that player rating system-based difficulty rating may be a viable and efficient way of improving both.</i></p>

<pre xml:space="preserve">
@inproceedings{sarkar2017engagement,
    Author = {Sarkar, Anurag and Williams, Michael and Deterding, Sebastian and Cooper, Seth},
    Title = {Engagement Effects of Player Rating System-based Matchmaking for Level Ordering in Human Computation Games},
    Booktitle = {FDG},
    Year = {2017}
}
</pre>
      </div>
    </td>
  </tr>

	<!--
  <tr>
    <td width="33%" valign="top"><a href="images/iccv15.png"><img src="images/iccv15.png" alt="sym" width="90%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="papers/iccv15.pdf" id="ICCV15">
      <heading>Constrained Convolutional Neural Networks for Weakly Supervised Segmentation</heading></a><br>
      <b>Deepak Pathak</b>, Philipp Kr&auml;henb&uuml;hl and Trevor Darrell<br>
      ICCV, 2015
      </p>

      <div class="paper" id="iccv15">
      <a href="papers/iccv15.pdf">pdf</a> |
      <a href="papers/iccv15_supp.pdf">supp</a> |
      <a href="javascript:toggleblock('iccv15_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('iccv15')" class="togglebib">bibtex</a> |
      <a href="http://arxiv.org/abs/1506.03648">arXiv</a> |
      <a href="https://github.com/pathak22/ccnn">code</a>

      <p align="justify"> <i id="iccv15_abs">We present an approach to learn a dense pixel-wise labeling from image-level tags. Each image-level tag imposes constraints on the output labeling of a Convolutional Neural Network (CNN) classifier. We propose Constrained CNN (CCNN), a method which uses a novel loss function to optimize for any set of linear constraints on the output space (i.e. predicted label distribution) of a CNN. Our loss formulation is easy to optimize and can be incorporated directly into standard stochastic gradient descent optimization. The key idea is to phrase the training objective as a biconvex optimization for linear models, which we then relax to nonlinear deep networks. Extensive experiments demonstrate the generality of our new learning framework. The constrained loss yields state-of-the-art results on weakly supervised semantic image segmentation. We further demonstrate that adding slightly more supervision can greatly improve the performance of the learning algorithm.</i></p>

<pre xml:space="preserve">
@inproceedings{pathakICCV15ccnn,
    Author = {Pathak, Deepak and
    Kr\"ahenb\"uhl, Philipp and
    Darrell, Trevor},
    Title = {Constrained Convolutional
    Neural Networks for Weakly
    Supervised Segmentation},
    Booktitle = {ICCV},
    Year = {2015}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="top"><a href="images/cvpr15.png"><img src="images/cvpr15.png" alt="sym" width="90%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="papers/cvpr15.pdf" id="CVPR15">
      <heading>Detector Discovery in the Wild: Joint Multiple Instance and Representation Learning</heading></a><br>
      Judy Hoffman, <b>Deepak Pathak</b>, Trevor Darrell and Kate Saenko<br>
      <br></p>

      <div class="paper" id="cvpr15">
      <a href="papers/cvpr15.pdf">pdf</a> |
      <a href="javascript:toggleblock('cvpr15_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('cvpr15')" class="togglebib">bibtex</a> |
      <a href="http://arxiv.org/abs/1412.1135">arXiv</a>

      <p align="justify"> <i id="cvpr15_abs">We develop methods for detector learning which exploit joint training over both weak (image-level) and strong (bounding box) labels and which transfer learned perceptual representations from strongly-labeled auxiliary tasks. Previous methods for weak-label learning often learn detector models independently using latent variable optimization, but fail to share deep representation knowledge across classes and usually require strong initialization. Other previous methods transfer deep representations from domains with strong labels to those with only weak labels, but do not optimize over individual latent boxes, and thus may miss specific salient structures for a particular category.  We propose a model that subsumes these previous approaches, and simultaneously trains a representation and detectors for categories with either weak or strong labels present. We provide a novel formulation of a joint multiple instance learning method that includes examples from classification-style data when available, and also performs domain transfer learning to improve the underlying detector representation. Our model outperforms known methods on ImageNet-200 detection with weak labels.</i></p>

<pre xml:space="preserve">
@inproceedings{pathakCVPR15,
    Author = {Hoffman, Judy and
    Pathak, Deepak and
    Darrell, Trevor and
    Saenko, Kate},
    Title = {Detector Discovery
    in the Wild: Joint Multiple
    Instance and Representation
    Learning},
    Booktitle = {CVPR},
    Year = {2015}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="top"><a href="images/iclr15.png"><img src="images/iclr15.png" alt="sym" width="90%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="papers/iclr15.pdf" id="ICLR15">
      <heading>Fully Convolutional Multi-Class Multiple Instance Learning</heading></a><br>
      <b>Deepak Pathak</b>, Evan Shelhamer, Jonathan Long, Trevor Darrell<br>
      <em>Workshop Track in International Conf. on Learning Representations (ICLR)</em> 2015<br>
      </p>

      <div class="paper" id="iclr15">
      <a href="papers/iclr15.pdf">pdf</a> |
      <a href="javascript:toggleblock('iclr15_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('iclr15')" class="togglebib">bibtex</a> |
      <a href="http://arxiv.org/abs/1412.7144">arXiv</a>

      <p align="justify"> <i id="iclr15_abs">Multiple instance learning (MIL) can reduce the need for costly annotation in tasks such as semantic segmentation by weakening the required degree of supervision. We propose a novel MIL formulation of multi-class semantic segmentation learning by a fully convolutional network. In this setting, we seek to learn a semantic segmentation model from just weak image-level labels. The model is trained end-to-end to jointly optimize the representation while disambiguating the pixel-image label assignment. Fully convolutional training accepts inputs of any size, does not need object proposal pre-processing, and offers a pixelwise loss map for selecting latent instances. Our multi-class MIL loss exploits the further supervision given by images with multiple labels. We evaluate this approach through preliminary experiments on the PASCAL VOC segmentation challenge.</i></p>

<pre xml:space="preserve">
@inproceedings{pathakICLR15,
    Author = {Pathak, Deepak and
    Shelhamer, Evan and
    Long, Jonathan and
    Darrell, Trevor},
    Title = {Fully Convolutional
    Multi-Class Multiple Instance
    Learning},
    Booktitle = {ICLR Workshop},
    Year = {2015}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="top"><a href="images/wacv15.png"><img src="images/wacv15.png" alt="sym" width="90%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="papers/wacv15.pdf" id="WACV15">
      <heading>Anomaly Localization in Topic-based Analysis of Surveillance Videos</heading></a><br>
      <b>Deepak Pathak</b>, Abhijit Sharang, Amitabha Mukerjee<br>
      WACV, 2015
      <br></p>

      <div class="paper" id="wacv15">
      <a href="papers/wacv15.pdf">pdf</a> |
      <a href="javascript:toggleblock('wacv15_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('wacv15')" class="togglebib">bibtex</a>

      <p align="justify"> <i id="wacv15_abs">Topic-models for video analysis have been used for unsupervised identification of normal activity in videos, thereby enabling the detection of anomalous actions. However, while intervals containing anomalies are detected, it has not been possible to localize the anomalous activities in such models. This is a challenging problem as the abnormal content is usually a small fraction of the entire video data and hence distinctions in terms of likelihood are unlikely. Here we propose a methodology to extend the topic based analysis with rich local descriptors incorporating quantized spatio-temporal gradient descriptors with image location and size information. The visual clips over this vocabulary are then represented in latent topic space using models like pLSA. Further, we introduce an algorithm to quantify the anomalous content in a video clip by projecting the learned topic space information. Using the algorithm, we detect whether the video clip is abnormal and if positive, localize the anomaly in spatio-temporal domain. We also contribute one real world surveillance video dataset for comprehensive evaluation of the proposed algorithm. Experiments are presented on the proposed and two other standard surveillance datasets.</i></p>

<pre xml:space="preserve">
@inproceedings{pathakWACV15,
    Author = {Pathak, Deepak and
    Sharang, Abhijit and
    Mukerjee, Amitabha},
    Title = {Anomaly Localization
    in Topic-based Analysis of
    Surveillance Videos},
    Booktitle = {WACV},
    Year = {2015}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="top"><a href="images/fg15.png"><img src="images/fg15.png" alt="sym" width="90%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="papers/fg15.pdf" id="FG15">
      <heading>Where is my Friend? - Person identification in Social Networks</heading></a><br>
      <b>Deepak Pathak</b>, Sai Nitish Satyavolu, Vinay P. Namboodiri<br>
      Automatic Face and Gesture Recognition (FG), 2015
      <br></p>

      <div class="paper" id="fg15">
      <a href="papers/fg15.pdf">pdf</a> |
      <a href="javascript:toggleblock('fg15_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('fg15')" class="togglebib">bibtex</a>

      <p align="justify"> <i id="fg15_abs">One of the interesting applications of computer vision is to be able to identify or detect persons in real world. This problem has been posed in the context of identifying people in television series or in multi-camera networks. However, a common scenario for this problem is to be able to identify people among images prevalent on social networks. In this paper we present a method that aims to solve this problem in real world conditions where the person can be in any pose, profile and orientation and the face itself is not always clearly visible. Moreover, we show that the problem can be solved with as weak supervision only a label whether the person is present or not, which is usually the case as people are tagged in social networks. This is challenging as there can be ambiguity in association of the right person. The problem is solved in this setting using a latent max-margin formulation where the identity of the person is the latent parameter that is classified. This framework builds on other off the shelf computer vision techniques for person detection and face detection and is able to also account for inaccuracies of these components. The idea is to model the complete person in addition to face, that too with weak supervision. We also contribute three real-world datasets that we have created for extensive evaluation of the solution. We show using these datasets that the problem can be effectively solved using the proposed method.</i></p>

<pre xml:space="preserve">
@inproceedings{pathakFG15,
    Author = {Pathak, Deepak and
    Satyavolu, Sai Nitish and
    Namboodiri, Vinay P.},
    Title = {Where is my Friend? -
    Person identification in Social
    Networks},
    Booktitle = {Automatic Face and
    Gesture Recognition (FG)},
    Year = {2015}
}
</pre>
      </div>
    </td>
  </tr>

  <tr>
    <td width="33%" valign="top"><center><a href="images/jpm15.jpg"><img src="images/jpm15.jpg" alt="sym" width="40%" style="border-radius:15px"></a></center></td>
    <td width="67%" valign="top">
      <p><a href="papers/jpm15.pdf" id="JPM15">
      <heading>A Comparison Of Forecasting Methods: Fundamentals, Polling, Prediction Markets, and Experts</heading></a><br>
      <b>Deepak Pathak</b>, David Rothschild and Miro Dud&iacute;k<br>
      Journal of Prediction Markets (JPM), 2015
      <br></p>

      <div class="paper" id="jpm15">
      <a href="papers/jpm15.pdf">pdf</a> |
      <a href="javascript:toggleblock('jpm15_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('jpm15')" class="togglebib">bibtex</a> |
      <a href="http://predictwise.com/blog/2014/03/oscars/">predictions2014</a> |
      <a href="http://predictwise.com/entertainment/2016-oscars" id="oscarPred">predictions2016</a>

      <p align="justify"> <i id="jpm15_abs">We compare Oscar forecasts derived from four data types (fundamentals, polling, prediction markets, and domain experts) across three attributes (accuracy, timeliness and cost effectiveness). Fundamentals-based forecasts are relatively expensive to construct, an attribute the academic literature frequently ignores, and update slowly over time, constraining their accuracy. However, fundamentals provide valuable insights into the relationship between key indicators for nominated movies and their chances of victory. For instance, we find that the performance in other awards shows is highly predictive of the Oscar victory whereas box office results are not. Polling- based forecasts have the potential to be both accurate and timely. Timeliness requires incentives for frequent responses by high-information users. Accuracy is achieved by a proper transformation of raw polls. Prediction market prices are accurate forecasts, but can be further improved by simple transformations of raw prices, yielding the most accurate forecasts in our study. Expert forecasts exhibit some characteristics of fundamental models, but are generally not comparatively accurate or timely. This study is unique in both comparing and aggregating four traditional data sources, and considering critical attributes beyond accuracy. We believe that the results of this study generalize to many other domains.</i></p>

<pre xml:space="preserve">
@inproceedings{pathakJPM15,
    Author = {Pathak, Deepak and
    Rothschild, David and
    Dudik, Miro},
    Title = {A Comparison Of Forecasting
    Methods: Fundamentals, Polling,
    Prediction Markets, and Experts},
    Booktitle = {Journal of Prediction Markets (JPM)},
    Year = {2015}
}
</pre>
      </div>
    </td>
  </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <br/>
  <tr><td><sectionheading>&nbsp;&nbsp;Technical Reports</sectionheading></td></tr>
</table>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td width="33%" valign="top"><a href="images/iclr16.png"><img src="images/iclr16.png" alt="sym" width="90%" style="border-radius:15px"></a></td>
    <td width="67%" valign="top">
      <p><a href="papers/iclr16.pdf" id="ICLR16">
      <heading>Constrained Structured Regression with Convolutional Neural Networks</heading></a><br>
      <b>Deepak Pathak</b>, Philipp Kr&auml;henb&uuml;hl, Stella X. Yu and Trevor Darrell<br>
      <em>arXiv:1511.07497</em>, 2015
      <br></p>

      <div class="paper" id="iclr16">
      <a href="papers/iclr16.pdf">pdf</a> |
      <a href="javascript:toggleblock('iclr16_abs')">abstract</a> |
      <a shape="rect" href="javascript:togglebib('iclr16')" class="togglebib">bibtex</a> |
      <a href="http://arxiv.org/abs/1511.07497">arXiv</a>

      <p align="justify"> <i id="iclr16_abs">Convolutional Neural Networks (CNNs) have recently emerged as the dominant model in computer vision. If provided with enough training data, they predict almost any visual quantity. In a discrete setting, such as classification, CNNs are not only able to predict a label but often predict a confidence in the form of a probability distribution over the output space. In continuous regression tasks, such a probability estimate is often lacking. We present a regression framework which models the output distribution of neural networks. This output distribution allows us to infer the most likely labeling following a set of physical or modeling constraints. These constraints capture the intricate interplay between different input and output variables, and complement the output of a CNN. However, they may not hold everywhere. Our setup further allows to learn a confidence with which a constraint holds, in the form of a distribution of the constrain satisfaction. We evaluate our approach on the problem of intrinsic image decomposition, and show that constrained structured regression significantly increases the state-of-the-art.</i></p>

<pre xml:space="preserve">
@inproceedings{pathakArxiv15,
    Author = {Pathak, Deepak and
    Kr\"ahenb\"uhl, Philipp and
    Yu, Stella X. and
    Darrell, Trevor},
    Title = {Constrained Structured
    Regression with Convolutional
    Neural Networks},
    Booktitle = {arXiv:1511.07497},
    Year = {2015}
}</pre>
      </div>
    </td>
  </tr>
</table>
-->
    <!--
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Teaching</sectionheading></td></tr>
</table>
<table width="100%" align="top" border="0" cellpadding="20">
  <tr>
    <td width="32%"><img src="images/cs189.jpg" alt="pacman" width="100%" style="border-radius:15px"></td>
    <td width="68%" valign="top">
      <p>
        <a href="http://www-inst.eecs.berkeley.edu/~cs189/fa15/"><heading>CS189/289: Introduction to Machine Learning - Fall '15 (GSI) </heading></a><br>
        <strong>Instructor</strong>: Prof. Alexei A. Efros and Dr. Isabelle Guyon<br>
      </p>
      <p>
        <a href="http://www-inst.eecs.berkeley.edu/~cs280/sp16"><heading>CS280: Computer Vision - Spring '16 (GSI)</heading></a><br>
        <strong>Instructor</strong>: Prof. Trevor Darrell and Prof. Alexei A. Efros<br>
      </p>
    </td>
  </tr>
</table> -->

    <!--
<table width="100%" align="center" border="0" cellpadding="10">
  <tr><td>
    <sectionheading>&nbsp;&nbsp;Selected Awards</sectionheading>
    <ul>
    <li> Facebook Graduate Fellowship (2018-2020)</li>
    <li> Nvidia Graduate Fellowship (2017-2018)</li>
    <li> Snapchat Inc. Graduate Fellowship (2017)</li>
    <li> Gold Medal in Computer Science at IIT Kanpur (2014)</li>
    <li> Best Undergraduate Thesis Award at IIT Kanpur (2014)</li>
    </ul>
  </td></tr>
</table> -->


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr><td><br><p align="right"><font size="2">
    Template: <a href="http://www.cs.berkeley.edu/~barron/">this</a>, <a href="http://www.cs.berkeley.edu/~sgupta/">this</a> and <a href="http://jeffdonahue.com/">this</a>
    </font></p></td></tr>
</table> 
  </td></tr>
</table>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('jpm15_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('fg15_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('wacv15_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('iclr15_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('cvpr15_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('iccv15_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('jmlr16_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('cvpr16_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('engagement17_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('predicting17_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('level17_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('meet18_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('comparing18_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('desire18_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('blending18_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('inferring19_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('arrays19_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('transforming19_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('controllable19_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('disjoint19_abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('game19_abs');
</script>
</body>

</html>
